## 大数据调度处理平台
* 核心思想，使用 dolphinscheduler 调度平台，串起整个大数据中台应用。
* 本文基础环境基于 centos6.8 + hadoop2.7.2 + MySql5.7.12 + zookeeper 3.4.13 + dolphinscheduler 2.0.5

### 安装 hadoop
* 详情查看 [hadoop安装](../hadoop/%E5%AE%89%E8%A3%85%E6%96%87%E6%A1%A3.md)

### 安装 zookeeper
* 详情查看 [Zookeeper 安装](../zookeeper/zookeeper%E5%AE%89%E8%A3%85.md)

### 安装 mysql
* 详情查看 [Zookeeper 安装](./%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%B0%83%E5%BA%A6%E5%A4%84%E7%90%86%E5%B9%B3%E5%8F%B0.md)

### 安装 dolphinscheduler
#### 配置免密
* 详情查看 [免密配置](../hbase/ssh%E5%85%8D%E5%AF%86.md)

#### 下载解压包
```shell
# 创建部署目录
mkdir -p /opt/dolphinscheduler;
cd /opt/dolphinscheduler;
# 解压缩
tar -zxvf apache-dolphinscheduler-2.0.5-bin.tar.gz -C /opt/dolphinscheduler;
mv apache-dolphinscheduler-2.0.5-bin dolphinscheduler-bin
```

#### 分离用户及赋权
```shell
# 设置用户名，请自行修改，后面以dolphinscheduler为例
useradd dolphinscheduler;
# 设置用户密码，请自行修改，后面以dolphinscheduler123为例
echo "dolphinscheduler123" | passwd --stdin dolphinscheduler
# 配置sudo免密
echo 'dolphinscheduler  ALL=(ALL)  NOPASSWD: NOPASSWD: ALL' >> /etc/sudoers
sed -i 's/Defaults    requirett/#Defaults    requirett/g' /etc/sudoers
```
```txt
 注意：
 - 因为是以 sudo -u {linux-user} 切换不同linux用户的方式来实现多租户运行作业，所以部署用户需要有 sudo 权限，而且是免密的。
 - 如果发现/etc/sudoers文件中有"Default requiretty"这行，也请注释掉
 - 如果用到资源上传的话，还需要在`HDFS或者MinIO`上给该部署用户分配读写的权限
```

#### 添加hosts映射
详情参考 [host配置](../host%E9%85%8D%E7%BD%AE.md)

#### 修改依赖环境变量
```shell
$ vi ./conf/env/dolphinscheduler_env.sh

### 按照服务器上的各个路径如实配置即可
export HADOOP_HOME=${HADOOP_HOME}
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export SPARK_HOME1=$SPARK_HOME_1
export SPARK_HOME2=$SPARK_HOME_2
export PYTHON_HOME=/opt/soft/python
export JAVA_HOME=$JAVA_HOME
export HIVE_HOME=/opt/soft/hive
export FLINK_HOME=$FLINK_HOME
export DATAX_HOME=/opt/soft/datax

export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$FLINK_HOME/bin:$DATAX_HOME/bin:$PATH
```

#### 修改install_config.conf
* 基本按照它的注释看一遍修改即可
```conf
# 主要服务器
masters="ds1,ds2"
# 集群工作服务器
workers="ds1:default,ds2:default,ds3:default,ds4:default"
# 报警服务器，ds1-4随便选一台
alertServer="ds3"
# 网关服务器，ds1-4随便选一台
apiServers="ds1"
# python网关服务器，ds1-4随便选一台
pythonGatewayServers="ds1"

# ---------------------------------------------------------
# DolphinScheduler ENV
# ---------------------------------------------------------
# JAVA_HOME, we recommend use same JAVA_HOME in all machine you going to install DolphinScheduler
# and this configuration only support one parameter so far.
javaHome="/opt/hadoop/jdk1.8.0_172"

# DolphinScheduler API service port, also this is your DolphinScheduler UI component's URL port, default value is 12345
apiServerPort="12345"
```

#### 数据库初始化
1. 上传相关mysql 驱动包到对应的 lib目录下，我这里用的版本是8.0.27
2. 修改 conf 目录下 application-mysql.yaml 中的下列配置
  ```yml
  spring:
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://127.0.0.1:3306/dolphinscheduler?useUnicode=true&characterEncoding=UTF-8
    username: root
    password: root
    hikari:
      connection-test-query: select 1
      minimum-idle: 5
      auto-commit: true
      validation-timeout: 3000
      pool-name: DolphinScheduler
      maximum-pool-size: 50
      connection-timeout: 30000
      idle-timeout: 600000
      leak-detection-threshold: 0
      initialization-fail-timeout: 1
  ```
  * 此处影响后面执行的创建数据库脚本
  ``` txt
  # ---------------------------------------------------------
  # Database
  # NOTICE: If database value has special characters, such as `.*[]^${}\+?|()@#&`, Please add prefix `\` for escaping.
  # ---------------------------------------------------------
  # The type for the metadata database
  # Supported values: ``postgresql``, ``mysql`, `h2``.
  DATABASE_TYPE=${DATABASE_TYPE:-"mysql"}

  # Spring datasource url, following <HOST>:<PORT>/<database>?<parameter> format, If you using mysql, you could use jdbc
  # string jdbc:mysql://127.0.0.1:3306/dolphinscheduler?useUnicode=true&characterEncoding=UTF-8 as example
  SPRING_DATASOURCE_URL=${SPRING_DATASOURCE_URL:-"jdbc:h2:mem:dolphinscheduler;MODE=MySQL;DB_CLOSE_DELAY=-1;DATABASE_TO_LOWER=true"}

  # Spring datasource username
  SPRING_DATASOURCE_USERNAME=${SPRING_DATASOURCE_USERNAME:-"sa"}

  # Spring datasource password
  SPRING_DATASOURCE_PASSWORD=${SPRING_DATASOURCE_PASSWORD:-""}
  ```
3. 修改并保存完后，执行 script 目录下的创建表及导入基础数据脚本
```shell
sh script/create-dolphinscheduler.sh
```

### 一键安装
* 完成以上所有配置以后，并且好好install_config.conf文件
  * 执行根目录下的 install.sh 脚本
  ```shell
  $./install.sh
  ```

### 常用脚本
```shell
# 在此目录下
$ cd script/
```
* 想看具体命令，打开对应脚本里面常用开始停止等命令都会在里面。


### hadoop Ha
```
# if resource.storage.type=HDFS and namenode HA is enabled, you need to copy core-site.xml and hdfs-site.xml to conf dir：
```
<font color=red>you need to copy core-site.xml and hdfs-site.xml to conf dir</font>
